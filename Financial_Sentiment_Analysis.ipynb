{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashpokra/Financial-Sentiment-Analysis/blob/main/Financial_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PLxoD2SQnxS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DYnysxmRYJP",
        "outputId": "89ddbafb-3882-4c7b-aa9d-b49c76363986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-12 03:00:15--  https://raw.githubusercontent.com/yashpokra/Financial-Sentiment-Analysis/main/financial%20-%20sentiment%20analysis.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 745117 (728K) [text/plain]\n",
            "Saving to: ‘financial - sentiment analysis.csv’\n",
            "\n",
            "\r          financial   0%[                    ]       0  --.-KB/s               \rfinancial - sentime 100%[===================>] 727.65K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-05-12 03:00:16 (151 MB/s) - ‘financial - sentiment analysis.csv’ saved [745117/745117]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Downloading dataset file from github\n",
        "!wget https://raw.githubusercontent.com/yashpokra/Financial-Sentiment-Analysis/main/financial%20-%20sentiment%20analysis.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfEGI7PlfdfP"
      },
      "outputs": [],
      "source": [
        "# Creating a data frame \n",
        "finance_dataset = pd.read_csv(\"/content/financial - sentiment analysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eL6TfUxFgBAF",
        "outputId": "1e3315fb-2e84-4b1d-d1dd-1b563d296c3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence Sentiment\n",
              "0  The GeoSolutions technology will leverage Bene...  positive\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
              "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
              "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
              "4  The Swedish buyout firm has sold its remaining...   neutral\n",
              "5    $SPY wouldn't be surprised to see a green close  positive\n",
              "6  Shell's $70 Billion BG Deal Meets Shareholder ...  negative\n",
              "7  SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative\n",
              "8  Kone 's net sales rose by some 14 % year-on-ye...  positive\n",
              "9  The Stockmann department store will have a tot...   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6379ece0-9f99-4887-ba22-2e18a645c66e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Kone 's net sales rose by some 14 % year-on-ye...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The Stockmann department store will have a tot...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6379ece0-9f99-4887-ba22-2e18a645c66e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6379ece0-9f99-4887-ba22-2e18a645c66e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6379ece0-9f99-4887-ba22-2e18a645c66e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "finance_dataset.head(10) # checking the first 10 rows "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVMsUb0rgTJ1"
      },
      "source": [
        "Converting the Sentiment labels into numerical form, so that we can develop a multiclass problem, where:\n",
        "\n",
        "`negative` = 0\n",
        "\n",
        "`neutral` = 1 \n",
        "\n",
        "`positive` = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JRQDZ02qhqpq",
        "outputId": "1355fc0b-9bb3-4daf-a6d0-1f7ba1e1e0ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  Sentiment\n",
              "0  The GeoSolutions technology will leverage Bene...          2\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...          0\n",
              "2  For the last quarter of 2010 , Componenta 's n...          2\n",
              "3  According to the Finnish-Russian Chamber of Co...          1\n",
              "4  The Swedish buyout firm has sold its remaining...          1\n",
              "5    $SPY wouldn't be surprised to see a green close          2\n",
              "6  Shell's $70 Billion BG Deal Meets Shareholder ...          0\n",
              "7  SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...          0\n",
              "8  Kone 's net sales rose by some 14 % year-on-ye...          2\n",
              "9  The Stockmann department store will have a tot...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e90ba999-accb-4e09-9eeb-194204e164b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Kone 's net sales rose by some 14 % year-on-ye...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The Stockmann department store will have a tot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e90ba999-accb-4e09-9eeb-194204e164b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e90ba999-accb-4e09-9eeb-194204e164b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e90ba999-accb-4e09-9eeb-194204e164b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset_dict = {\"negative\": 0, \"neutral\": 1, \"positive\":2} # Creating dictionary \n",
        "finance_dataset[\"Sentiment\"].replace(dataset_dict, inplace = True) # set inplace to True, so that it will directly the modify the changes to the dataframe directly\n",
        "finance_dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l12drMLMRNq9",
        "outputId": "4c1f04cf-4874-48f5-ea25-8afd45e12424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas(Index=2593, Sentence=\"The Board of Directors proposes to the Shareholders ' Meeting on 18 March 2010 that the company would pay dividend for the financial year January 1 - December 31 , 2009 , EUR 0.02 per share .\", Sentiment=1)\n",
            "\n",
            "Pandas(Index=2594, Sentence='RBS chairman admits surprise at size of regulatory penalties', Sentiment=0)\n",
            "\n",
            "Pandas(Index=2595, Sentence='Ramirent Finland is the domestic unit of machinery rental company Ramirent Oyj HEL : RMR1V .', Sentiment=1)\n",
            "\n",
            "Pandas(Index=2596, Sentence='Like all other mechanical pipettors from Biohit , also Proline Plus is CE-IVD marked and comes with a 3-year warranty .', Sentiment=1)\n",
            "\n",
            "Pandas(Index=2597, Sentence=\"Earlier today , Geberit 's Finnish rival Uponor OYJ cut its full-year sales growth forecast to 6 pct from 10 pct , blaming tough conditions in Germany and the US , as well as currency factors .\", Sentiment=1)\n",
            "\n",
            "Pandas(Index=2598, Sentence='The invention carries International Patent Publication No. .', Sentiment=1)\n",
            "\n",
            "Pandas(Index=2599, Sentence='Blyk is launching first in the UK market in mid-2007 , with other markets to follow .', Sentiment=1)\n",
            "\n",
            "Pandas(Index=2600, Sentence='Petrofac books further Â£30m cost for Shetland gas terminal delays', Sentiment=0)\n",
            "\n",
            "Pandas(Index=2601, Sentence='Swedish engineering consultant firm Etteplan is to establish a unit in town Borl+ñnge , by the turn of the month March-April 2008 .', Sentiment=1)\n",
            "\n",
            "Pandas(Index=2602, Sentence='The agreement was signed with Biohit Healthcare Ltd , the UK-based subsidiary of Biohit Oyj , a Finnish public company which develops , manufactures and markets liquid handling products and diagnostic test systems .', Sentiment=2)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Focusing on seeing random datasets from the finance dataset. \n",
        "import random\n",
        "i = random.randint(0, len(finance_dataset)-10)\n",
        "for row in finance_dataset[[\"Sentence\", \"Sentiment\"]][i: i + 10].itertuples():\n",
        "  print(row)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoseFyvrkAie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5f32c6-3958-4dd3-969e-7edfb75f16fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4673"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Utilizing scikit learn to split the dataset into training and testing datasets \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentence, test_sentence, train_sentiment, test_sentiment  = train_test_split(finance_dataset[\"Sentence\"].to_numpy(), finance_dataset[\"Sentiment\"].to_numpy(), train_size = 0.8, random_state = 43)\n",
        "len(train_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7_TNz-MrY1",
        "outputId": "74b25248-4d69-4991-8db1-757d0df8c2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences for training dataset: 5257\n",
            "Total sentences for the validation dataset: 585\n",
            "Total sentences for test dataset: 1169\n",
            "Total sentences in the whole dataset: 5842\n"
          ]
        }
      ],
      "source": [
        "# Splitting training data into validation data\n",
        "train_sentence, validation_sentence, train_sentiment, val_sentiment = train_test_split(finance_dataset[\"Sentence\"].to_numpy(), finance_dataset[\"Sentiment\"].to_numpy(), test_size = 0.1, random_state = 43)\n",
        "\n",
        "print(f\"Total sentences for training dataset: {len(train_sentence)}\")\n",
        "print(f\"Total sentences for the validation dataset: {len(validation_sentence)}\")\n",
        "print(f\"Total sentences for test dataset: {len(test_sentence)}\")\n",
        "print(f\"Total sentences in the whole dataset: {len(finance_dataset)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFGOOvPnQyxe",
        "outputId": "c5f73118-2774-4444-edf2-1a6ad1e9e24a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Elcoteq 's global service offering covers the entire lifecycle of products , from product development to after-market services .\",\n",
              "       'The inventors are Mukkavilli Krishna Kiran , Sabharwal Ashutosh and Aazhang Behnaam .',\n",
              "       'The group posted net sales of 35.3 mln euro $ 46.5 mln and an operating profit of 760,000 euro $ 1.0 mln in 2005 .',\n",
              "       'Delivery is expected to take place later this month .',\n",
              "       'Both operating profit and net sales for the six-month period increased , respectively , from EUR13 .8 m and EUR143 .6 m , as compared to the corresponding period in 2007 .',\n",
              "       '$BAC $ADSK $NFLX long this morning',\n",
              "       'Mercator will use the software for its logistic , retail and wholesale operations in Slovenia and its other markets in southeastern Europe .',\n",
              "       \"South African Sappi will become the largest foreign forest industry company operating in Finland as a result of the acquisition Finnish M-real Corporation 's Graphic Papers Business unit .\",\n",
              "       'The administrators have indicated a need for 900 job cuts at the Irish insurer over the next 15 months .',\n",
              "       'Finnish meat company Atria can no longer promise a sufficient amount of domestic beef to its customers .'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_sentence[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMv63HCXbk8T",
        "outputId": "624b6181-6d3c-4dc9-dccf-2e263840bedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Elcoteq', \"'s\", 'global', 'service', 'offering', 'covers', 'the', 'entire', 'lifecycle', 'of', 'products', ',', 'from', 'product', 'development', 'to', 'after-market', 'services', '.']\n",
            "['The', 'inventors', 'are', 'Mukkavilli', 'Krishna', 'Kiran', ',', 'Sabharwal', 'Ashutosh', 'and', 'Aazhang', 'Behnaam', '.']\n",
            "['The', 'group', 'posted', 'net', 'sales', 'of', '35.3', 'mln', 'euro', '$', '46.5', 'mln', 'and', 'an', 'operating', 'profit', 'of', '760,000', 'euro', '$', '1.0', 'mln', 'in', '2005', '.']\n",
            "['Delivery', 'is', 'expected', 'to', 'take', 'place', 'later', 'this', 'month', '.']\n",
            "['Both', 'operating', 'profit', 'and', 'net', 'sales', 'for', 'the', 'six-month', 'period', 'increased', ',', 'respectively', ',', 'from', 'EUR13', '.8', 'm', 'and', 'EUR143', '.6', 'm', ',', 'as', 'compared', 'to', 'the', 'corresponding', 'period', 'in', '2007', '.']\n",
            "['$BAC', '$ADSK', '$NFLX', 'long', 'this', 'morning']\n",
            "['Mercator', 'will', 'use', 'the', 'software', 'for', 'its', 'logistic', ',', 'retail', 'and', 'wholesale', 'operations', 'in', 'Slovenia', 'and', 'its', 'other', 'markets', 'in', 'southeastern', 'Europe', '.']\n",
            "['South', 'African', 'Sappi', 'will', 'become', 'the', 'largest', 'foreign', 'forest', 'industry', 'company', 'operating', 'in', 'Finland', 'as', 'a', 'result', 'of', 'the', 'acquisition', 'Finnish', 'M-real', 'Corporation', \"'s\", 'Graphic', 'Papers', 'Business', 'unit', '.']\n",
            "['The', 'administrators', 'have', 'indicated', 'a', 'need', 'for', '900', 'job', 'cuts', 'at', 'the', 'Irish', 'insurer', 'over', 'the', 'next', '15', 'months', '.']\n",
            "['Finnish', 'meat', 'company', 'Atria', 'can', 'no', 'longer', 'promise', 'a', 'sufficient', 'amount', 'of', 'domestic', 'beef', 'to', 'its', 'customers', '.']\n"
          ]
        }
      ],
      "source": [
        "for i in train_sentence[0:10]:\n",
        "  print(i.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7xZr8UsmkuP",
        "outputId": "e28c0117-2ba0-4cda-8d54-521e05afa955"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5257"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNDfHz0QdKj4",
        "outputId": "8d46d491-75e3-46a7-e014-c0aca84a3fc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 110829)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Total elements in training_sentence before splitting \n",
        "before_split = len(train_sentence)\n",
        "\n",
        "\n",
        "# Total elements in training_sentence after splitting \n",
        "max_vocab = sum([len(i.split()) for i in train_sentence]) \n",
        "\n",
        "maximum_length = round(max_vocab/before_split)\n",
        "maximum_length, max_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4x_33C0C-no"
      },
      "outputs": [],
      "source": [
        "# Converting the text to numbers utilzing tokenization. \n",
        "import keras  \n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding \n",
        "\n",
        "vectorizer_layer = tf.keras.layers.TextVectorization (\n",
        "    max_tokens = max_vocab, # max limit for unique words\n",
        "    split=\"whitespace\",\n",
        "    ngrams = None,\n",
        "    output_mode = \"int\", \n",
        "    output_sequence_length = maximum_length\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2_8lBRwx5iu"
      },
      "outputs": [],
      "source": [
        "vectorizer_layer.adapt(train_sentence) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNfVY0XYykMW",
        "outputId": "b3b14be8-6223-462b-87be-96969b319535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f63a20f2210>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "embedding_layer  = tf.keras.layers.Embedding(\n",
        "  input_dim = max_vocab, \n",
        "  output_dim = 128,\n",
        "  input_length = maximum_length\n",
        ")\n",
        "embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDE0BQFK81R8",
        "outputId": "287e61f8-a6a2-4a71-a0b8-060dbeab73e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 21, 128), dtype=float32, numpy=\n",
              "array([[[-0.0325613 ,  0.03857769, -0.01384035, ...,  0.03748462,\n",
              "         -0.03352014, -0.02825221],\n",
              "        [-0.03982903,  0.01831805, -0.0169531 , ...,  0.00642641,\n",
              "         -0.00711645, -0.03672038],\n",
              "        [-0.00190771,  0.02690012,  0.04577408, ...,  0.0015307 ,\n",
              "         -0.00563933, -0.03532264],\n",
              "        ...,\n",
              "        [-0.0007658 , -0.03120708,  0.000804  , ..., -0.04641673,\n",
              "          0.01989922, -0.01390143],\n",
              "        [-0.0007658 , -0.03120708,  0.000804  , ..., -0.04641673,\n",
              "          0.01989922, -0.01390143],\n",
              "        [-0.0007658 , -0.03120708,  0.000804  , ..., -0.04641673,\n",
              "          0.01989922, -0.01390143]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "random_sentence = random.choice(train_sentence)\n",
        "sample_em = embedding_layer(vectorizer_layer([random_sentence]))\n",
        "sample_em"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kki4ZN9KV9yq"
      },
      "source": [
        "Baseline Model using Naives Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XrZuyJafZ21",
        "outputId": "c1e5414c-c8dd-4ed5-a60e-c571c284511b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1,\n",
              "       2, 1, 0, 1, 1, 0, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1,\n",
              "       1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1,\n",
              "       0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2,\n",
              "       1, 0, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 1, 2, 1, 1, 1, 2, 1, 2, 0, 2,\n",
              "       1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 1, 1, 0,\n",
              "       2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 1,\n",
              "       2, 1, 0, 2, 1, 2, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2,\n",
              "       2, 2, 0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 1, 1, 2, 0, 2, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2,\n",
              "       1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 0, 1, 2,\n",
              "       0, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
              "       0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 2, 0,\n",
              "       1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1, 0, 2, 2, 1, 1, 2, 1, 1, 1, 0,\n",
              "       2, 2, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2, 2, 2, 1, 1,\n",
              "       1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n",
              "       1, 2, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 0, 2, 0, 2, 1, 1, 2, 1, 2, 0,\n",
              "       2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 1, 0,\n",
              "       1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 1, 2, 1, 1,\n",
              "       1, 2, 1, 2, 1, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 2, 1, 1, 2, 2, 1,\n",
              "       1, 0, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 2, 1,\n",
              "       1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1,\n",
              "       2, 0, 1, 1, 0, 1, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
              "       1, 2, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "val_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLyoqwfdhDKW",
        "outputId": "3c81a8cb-ae18-4d40-81c7-90c88df495bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Elcoteq 's global service offering covers the entire lifecycle of products , from product development to after-market services .\",\n",
              "       'The inventors are Mukkavilli Krishna Kiran , Sabharwal Ashutosh and Aazhang Behnaam .',\n",
              "       'The group posted net sales of 35.3 mln euro $ 46.5 mln and an operating profit of 760,000 euro $ 1.0 mln in 2005 .',\n",
              "       ...,\n",
              "       'Paper companies were in negative territories , with Stora Enso R shedding 1.62 pct to 12.73 eur , UPM-Kymmene down 0.80 pct at 18.64 eur and M-real B 0.18 pct lower at 5.57 eur .',\n",
              "       'The company plans to close two of the three lines at the plant , where some 450 jobs are under threat .',\n",
              "       'Sales of mid-strength beer decreased by 40 % .'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHJNmrHtV4k7",
        "outputId": "80de0fd2-d099-4ad7-a2ec-c5179b6121c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "       2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1,\n",
              "       1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2,\n",
              "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
              "       1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
              "       1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2,\n",
              "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1,\n",
              "       1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "baseline = Pipeline(\n",
        "    [\n",
        "     (\"tfid\", TfidfVectorizer()),  #extractor - extracting features \n",
        "     (\"clf\", MultinomialNB()),  # classifier - will classify the patterns \n",
        "    ])\n",
        "baseline.fit(train_sentence, train_sentiment)\n",
        "baseline_pred = baseline.predict(validation_sentence)\n",
        "\n",
        "baseline_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VgutmgAmdAy",
        "outputId": "4755b377-c03f-4f77-bc4b-3a933712fb6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCZuSnGhu0oK",
        "outputId": "8539fe61-1074-4ff3-a3f4-1437c59014f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((585,), (585,))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "val_sentiment.shape, baseline_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8R2p2lEki8C"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score\n",
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "  accuracy_metric = accuracy_score(y_true, y_pred)\n",
        "  precession_metric = precision_score(y_true, y_pred, average = \"weighted\") \n",
        "  recall_metric = recall_score(y_true, y_pred, average = \"weighted\")\n",
        "  f1_metric = f1_score(y_true, y_pred, average = \"weighted\")\n",
        "   \n",
        "  model_metrics = {\"accuracy_score\": accuracy_metric, \"precession_score\": precession_metric, \"recall_score\": recall_metric, \"f1_score\": f1_metric}\n",
        "  return(model_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhGNKf_qm-4Q",
        "outputId": "5ee8f0c7-34a2-4e01-e0df-a3f04896c221"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy_score': 0.6512820512820513,\n",
              " 'f1_score': 0.5811778710568056,\n",
              " 'precession_score': 0.6511610200596359,\n",
              " 'recall_score': 0.6512820512820513}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "baseline_results = get_metrics(val_sentiment, baseline_pred)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentence.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCbRHIz6h3CI",
        "outputId": "2f454d4a-8444-4f81-e382-3c122d0450d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5257,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE_XUPThu829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e6494b-2e30-4106-8b94-d094bc2198e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5257,), (585,), (5257,), (585,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "train_sentence\n",
        "train_sentence.shape, validation_sentence.shape, train_sentiment.shape, val_sentiment.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1: Simple Dense Layers"
      ],
      "metadata": {
        "id": "solLVAw8u1uM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJZ9zprCpYb8",
        "outputId": "e063d8ce-8d78-4258-a3bb-bae4de9a4c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 21)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 21, 128)           14186112  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 21, 10)            1290      \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 10)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,187,435\n",
            "Trainable params: 14,187,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(47)\n",
        "inputs = layers.Input(shape = (1, ) , dtype = \"string\")\n",
        "x = vectorizer_layer(inputs)\n",
        "# print(x.shape)\n",
        "x = embedding_layer(x)\n",
        "x = tf.keras.layers.Dense(10, activation = \"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "outputs = layers.Dense(3, activation = \"softmax\")(x)\n",
        "# print(outputs.shape)\n",
        "first_model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "first_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg4csNQooDkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27776474-99a1-4519-8f45-0c319ec772d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "165/165 [==============================] - 7s 12ms/step - loss: 0.9248 - accuracy: 0.5929 - val_loss: 0.8165 - val_accuracy: 0.6615\n",
            "Epoch 2/5\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.6952 - accuracy: 0.7295 - val_loss: 0.7288 - val_accuracy: 0.6667\n",
            "Epoch 3/5\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.5208 - accuracy: 0.7875 - val_loss: 0.7486 - val_accuracy: 0.6615\n",
            "Epoch 4/5\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.3957 - accuracy: 0.8421 - val_loss: 0.8090 - val_accuracy: 0.6496\n",
            "Epoch 5/5\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.3166 - accuracy: 0.8636 - val_loss: 0.8949 - val_accuracy: 0.6308\n"
          ]
        }
      ],
      "source": [
        "first_model.compile(loss = \"sparse_categorical_crossentropy\", \n",
        "                    optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "first_hist = first_model.fit(train_sentence, \n",
        "                            train_sentiment, epochs = 5,\n",
        "                            validation_data = (validation_sentence, val_sentiment))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "first_model_pred = first_model.predict(validation_sentence)\n",
        "first_model_pred_round = tf.round(first_model_pred)\n",
        "first_model_pred_round"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioA--shc7Rer",
        "outputId": "9d8e992e-1cbf-43cb-c281-7d36a68c40d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(585, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using tf.argmax to get the largest values along the axis of the tensor\n",
        "\n",
        "first_model_pred_classes = tf.argmax(first_model_pred_round, axis = 1)\n",
        "\n",
        "first_model_pred_classes"
      ],
      "metadata": {
        "id": "KvRpAKEAK-PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9a9c39-164f-4e69-a73e-6eae977a1eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(585,), dtype=int64, numpy=\n",
              "array([1, 1, 0, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 0, 2, 1, 1, 0, 0, 0, 1,\n",
              "       0, 2, 1, 1, 0, 2, 2, 1, 1, 2, 0, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0,\n",
              "       1, 1, 2, 1, 2, 2, 2, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2,\n",
              "       1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 0, 1, 0, 2, 1, 1, 0, 1, 0,\n",
              "       2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1,\n",
              "       2, 1, 1, 2, 1, 0, 1, 2, 2, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 0, 2, 2,\n",
              "       2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0,\n",
              "       1, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2,\n",
              "       1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 0,\n",
              "       1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 0, 2, 1,\n",
              "       0, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 1, 2, 2, 1, 1, 0, 2, 1, 1, 2, 1,\n",
              "       2, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 0, 2, 2, 1, 1,\n",
              "       0, 1, 1, 2, 0, 1, 1, 0, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1,\n",
              "       2, 2, 0, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 1, 0,\n",
              "       2, 1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 0, 2, 1, 2,\n",
              "       1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0,\n",
              "       1, 2, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 2,\n",
              "       1, 0, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 1, 1, 2, 2, 1,\n",
              "       1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       2, 1, 1, 2, 1, 1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2,\n",
              "       1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2,\n",
              "       0, 1, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1,\n",
              "       1, 1, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVoeym7tL03u",
        "outputId": "5cad37b2-b7c5-46a1-b675-ea671d0d57d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1,\n",
              "       2, 1, 0, 1, 1, 0, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1,\n",
              "       1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1,\n",
              "       0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2,\n",
              "       1, 0, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 1, 2, 1, 1, 1, 2, 1, 2, 0, 2,\n",
              "       1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 1, 1, 0,\n",
              "       2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 1,\n",
              "       2, 1, 0, 2, 1, 2, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2,\n",
              "       2, 2, 0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 1, 1, 2, 0, 2, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2,\n",
              "       1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 0, 1, 2,\n",
              "       0, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
              "       0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 2, 0,\n",
              "       1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1, 0, 2, 2, 1, 1, 2, 1, 1, 1, 0,\n",
              "       2, 2, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2, 2, 2, 1, 1,\n",
              "       1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n",
              "       1, 2, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 0, 2, 0, 2, 1, 1, 2, 1, 2, 0,\n",
              "       2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 1, 0,\n",
              "       1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 1, 2, 1, 1,\n",
              "       1, 2, 1, 2, 1, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 2, 1, 1, 2, 2, 1,\n",
              "       1, 0, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 2, 1,\n",
              "       1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1,\n",
              "       2, 0, 1, 1, 0, 1, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
              "       1, 2, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_model_results = get_metrics(y_true = val_sentiment, y_pred = first_model_pred_classes)\n",
        "first_model_results"
      ],
      "metadata": {
        "id": "IVFAWnSCz_8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3296ee1-3da3-48e4-9b8e-33e68ee5aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy_score': 0.6341880341880342,\n",
              " 'f1_score': 0.635478466392317,\n",
              " 'precession_score': 0.6375725220071585,\n",
              " 'recall_score': 0.6341880341880342}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reccurent Neural Networks"
      ],
      "metadata": {
        "id": "yqaOU-BTu7e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(47)\n",
        "inputs = layers.Input(shape = (1, ) , dtype = \"string\")\n",
        "\n",
        "x = vectorizer_layer(inputs)\n",
        "\n",
        "second_model_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim = max_vocab,\n",
        "    output_dim = 128,\n",
        "    input_length = maximum_length\n",
        ")\n",
        "\n",
        "x = second_model_embedding(x)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.LSTM(52, return_sequences = True)(x)\n",
        "x = tf.keras.layers.LSTM(52)(x)\n",
        "\n",
        "outputs = layers.Dense(3, activation = \"softmax\")(x)\n",
        "\n",
        "\n",
        "second_model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "second_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yifUDhXtulAc",
        "outputId": "781a6479-06ea-4ba7-a382-dbb3e992bc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 21)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 21, 128)           14186112  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 21, 52)            37648     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 52)                21840     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 159       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,245,759\n",
            "Trainable params: 14,245,759\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the model\n",
        "\n",
        "second_model.compile(loss = \"sparse_categorical_crossentropy\", \n",
        "                    optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "second_hist = second_model.fit(train_sentence, \n",
        "                            train_sentiment, epochs = 5,\n",
        "                            validation_data = (validation_sentence, val_sentiment))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4sJIk4rMU-5",
        "outputId": "51b4e42c-1afb-4356-c480-2c9f04bb3b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "165/165 [==============================] - 8s 18ms/step - loss: 0.8697 - accuracy: 0.6213 - val_loss: 0.7311 - val_accuracy: 0.7094\n",
            "Epoch 2/5\n",
            "165/165 [==============================] - 2s 14ms/step - loss: 0.4922 - accuracy: 0.7930 - val_loss: 0.7314 - val_accuracy: 0.6872\n",
            "Epoch 3/5\n",
            "165/165 [==============================] - 2s 14ms/step - loss: 0.2647 - accuracy: 0.8701 - val_loss: 1.0191 - val_accuracy: 0.6752\n",
            "Epoch 4/5\n",
            "165/165 [==============================] - 2s 15ms/step - loss: 0.1938 - accuracy: 0.8912 - val_loss: 1.2004 - val_accuracy: 0.6701\n",
            "Epoch 5/5\n",
            "165/165 [==============================] - 2s 14ms/step - loss: 0.1514 - accuracy: 0.9039 - val_loss: 1.4144 - val_accuracy: 0.6906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_model_pred = second_model.predict(validation_sentence)\n",
        "second_model_pred_round = tf.round(second_model_pred)\n",
        "second_model_pred_classes = tf.argmax(second_model_pred_round, axis = 1)\n",
        "second_model_pred_classes[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMRr9nQRMq-_",
        "outputId": "0da3ba0f-9c96-488f-acfe-3d0c6ea9515b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 2, 2, 1, 1, 1, 1,\n",
              "       2, 1, 2, 2, 1, 2, 1, 0, 2, 1, 1, 2, 2, 1, 0, 2, 1, 1, 1, 0, 2, 1,\n",
              "       1, 2, 1, 1, 1, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_model_results = get_metrics(y_true = val_sentiment, y_pred =second_model_pred_classes)\n",
        "second_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2IWQ8W0M5VP",
        "outputId": "d3cacf59-3132-482f-cc1a-38255fa76e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy_score': 0.694017094017094,\n",
              " 'f1_score': 0.6831083713352083,\n",
              " 'precession_score': 0.6762557801920915,\n",
              " 'recall_score': 0.694017094017094}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on Creating a Dataframe, and comparing the results of two models and the baseline. We can see that the second_model(RNN- LSTM) performs the best. "
      ],
      "metadata": {
        "id": "ZdlXrwZtU_yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_results = pd.DataFrame({\"baseline\": baseline_results,  # will create a DataFrame based on the results of the models and the baseline\n",
        "              \"first_model(simple dense layers)\": first_model_results,  \n",
        "              \"second_model(RNN- LSTM)\": second_model_results})\n",
        "total_model_results = total_results.transpose()\n",
        "total_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8hkHnMfUOxsr",
        "outputId": "cb056b80-58a0-46b9-b67a-e18d5ce3b5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  accuracy_score  precession_score  \\\n",
              "baseline                                0.651282          0.651161   \n",
              "first_model(simple dense layers)        0.634188          0.637573   \n",
              "second_model(RNN- LSTM)                 0.694017          0.676256   \n",
              "\n",
              "                                  recall_score  f1_score  \n",
              "baseline                              0.651282  0.581178  \n",
              "first_model(simple dense layers)      0.634188  0.635478  \n",
              "second_model(RNN- LSTM)               0.694017  0.683108  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb5bf007-5858-4dda-b72a-97464a9adf81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_score</th>\n",
              "      <th>precession_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.651282</td>\n",
              "      <td>0.651161</td>\n",
              "      <td>0.651282</td>\n",
              "      <td>0.581178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_model(simple dense layers)</th>\n",
              "      <td>0.634188</td>\n",
              "      <td>0.637573</td>\n",
              "      <td>0.634188</td>\n",
              "      <td>0.635478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>second_model(RNN- LSTM)</th>\n",
              "      <td>0.694017</td>\n",
              "      <td>0.676256</td>\n",
              "      <td>0.694017</td>\n",
              "      <td>0.683108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb5bf007-5858-4dda-b72a-97464a9adf81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb5bf007-5858-4dda-b72a-97464a9adf81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb5bf007-5858-4dda-b72a-97464a9adf81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xJBW4OBkh4SR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Financial Sentiment Analysis",
      "provenance": [],
      "authorship_tag": "ABX9TyOMANm17kMI8r6nf80lWVbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}